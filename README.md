# ADS-ScenarioQA: Evaluating Test Scenario Reasoning Capabilities of Large Language Models

## Overview 
ScenarioQA is an in-depth test and evaluation of the capabilities of different LLMs using high-quality QA pairs generated by GPT-4, which we picked due to it having comparable logical reasoning compared to other LLMs. We use the ontology and questions generated for each reasoning category we call LiteLLM to determine the logical capabilities of several LLMs in comparison simultaneously when it comes to driving conditions.

## Python Guidance Library
We used the Python Guidance library due to its ability to call many LLMs including GPT with more efficiency compared to conventional prompting and chaining methods.
### Question Generation
All of the scripts for question generation are in the QA Template folder. To run them, follow the steps below:
1. Make sure you have the proper environmental variables set on your local PC. We are using GPT-4 for the guidance prompts so it was necessary to set the API key in the environmental variables to ensure the prompts run properly.
2. Install all the dependencies: You need Python Version 3.10 or above, pip install guidance, pip install ...
3. The prompt is a block of text with the following sections: . . . . . , you can modify the 

### Ontology Creation

## LiteLLM
Most of the directions can be found on the official LiteLLM website. 
1. Install Dependencies, pip install Flask, pip install litellm, pip install waitress 


